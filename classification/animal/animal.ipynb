{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Released under MIT License\n",
    "\n",
    "Copyright (c) 2013 Mark Otto.\n",
    "\n",
    "Copyright (c) 2017 Andrew Fong.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/borhanitrash/animal-image-classification-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "\n",
    "***Dataset Summary***\n",
    "\n",
    "The Animal Image Classification Dataset is a comprehensive collection of images tailored for the development and evaluation of machine learning models in the field of computer vision. It contains 3,000 JPG images, carefully segmented into three classes representing common pets and wildlife: cats, dogs, and snakes.\n",
    "\n",
    "Dataset Contents\n",
    "cats/: A set of 1,000 JPG images of cats, showcasing a wide array of breeds, environments, and postures.\n",
    "\n",
    "dogs/: A diverse compilation of 1,000 dog images, capturing a multitude of breeds in various activities and settings.\n",
    "\n",
    "snakes/: An assortment of 1,000 images of snakes, depicting numerous species in both natural and controlled habitats. Image Details:\n",
    "\n",
    "Resolution: Each image maintains a uniform resolution of 256x256 pixels, providing clarity and consistency for model training.\n",
    "\n",
    "File Format: JPG Color Space: RGB\n",
    "\n",
    "Intended Applications\n",
    "This dataset is primed for use in developing and testing AI models specialized in multi-class animal recognition. It offers valuable resources for researchers and hobbyists in fields such as zoology, pet technology, and biodiversity conservation.\n",
    "\n",
    "Acknowledgements and Licensing\n",
    "This dataset is a collective effort of various photographers and organizations. All images are distributed with permissions for academic and non-commercial usage, provided that proper attribution is given to the original sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Про набір даних\n",
    "\n",
    "***Короткий опис набору даних***\n",
    "\n",
    "Набір даних «Класифікація зображень тварин» - це повна колекція зображень, призначена для розробки та оцінки моделей машинного навчання в галузі комп'ютерного зору. Він містить 3 000 зображень у форматі JPG, ретельно сегментованих на три класи, що представляють найпоширеніших домашніх та диких тварин: котів, собак та змій.\n",
    "\n",
    "Зміст набору даних\n",
    "cats/: Набір з 1,000 JPG зображень котів, що демонструють широкий спектр порід, середовищ та поз.\n",
    "\n",
    "собаки/: Різноманітна добірка з 1,000 зображень собак, що демонструє безліч порід у різних видах діяльності та середовищах.\n",
    "\n",
    "змії/: Підбірка з 1 000 зображень змій, на яких зображені численні види як у природному, так і в контрольованому середовищі існування. Деталі зображення:\n",
    "\n",
    "Роздільна здатність: Кожне зображення має однакову роздільну здатність 256x256 пікселів, що забезпечує чіткість і послідовність для навчання моделі.\n",
    "\n",
    "Формат файлу: JPG Колірний простір: RGB\n",
    "\n",
    "Призначення\n",
    "Цей набір даних призначений для використання при розробці та тестуванні моделей штучного інтелекту, що спеціалізуються на розпізнаванні тварин різних класів. Він пропонує цінні ресурси для дослідників і аматорів у таких галузях, як зоологія, технології для домашніх тварин і збереження біорізноманіття.\n",
    "\n",
    "Подяки та ліцензування\n",
    "Цей набір даних є результатом колективних зусиль різних фотографів та організацій. Всі зображення розповсюджуються з дозволом на академічне та некомерційне використання за умови належного посил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications import MobileNetV2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "data_dir = '../../classification/animal/data/'\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    "    \n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "class_names = train_ds.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    print(\"First label (one-hot):\", labels[0].numpy())\n",
    "    print(\"Corresponding class:\", tf.argmax(labels[0]).numpy())\n",
    "    print(\"Class name:\", train_ds.class_names[tf.argmax(labels[0]).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Кількість зразків у класах (тренувальний батч):\")\n",
    "    print(np.sum(labels, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(os.listdir(data_dir)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Label shape:\", labels.shape)  # Має бути (batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda img, lbl: (img, tf.one_hot(lbl, depth=len(class_names))))\n",
    "test_ds = test_ds.map(lambda img, lbl: (img, tf.one_hot(lbl, depth=len(class_names))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_counts = Counter()\n",
    "for _, labels in train_ds.unbatch():\n",
    "    class_idx = tf.argmax(labels).numpy()\n",
    "    total_counts[class_idx] += 1\n",
    "\n",
    "print(\"Кількість зразків у кожному класі (весь train_ds):\")\n",
    "for idx, count in sorted(total_counts.items()):\n",
    "    print(f\"{train_ds.class_names[idx]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцесинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(256, 256, 3)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(3, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     epochs=10,\n",
    "#     validation_data=test_ds\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',    \n",
    "    patience=3,          \n",
    "    restore_best_weights=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=30, \n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(img_path, model, class_names, image_size=(256, 256)):\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    # pred = model.predict(img_array)[0]\n",
    "    pred = tf.squeeze(model.predict(img_array)).numpy()\n",
    "\n",
    "    predicted_class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Прогноз: {class_names[predicted_class_idx]} ({confidence:.2f})\")\n",
    "    plt.show()\n",
    "\n",
    "predict_and_plot('../../classification/animal/data/snakes/2_0958.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0003.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0005.jpg', model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(256, 256, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False  # Спочатку заморожуємо\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(img_path, model, class_names, image_size=(256, 256)):\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    pred = model.predict(img_array, verbose=0)[0]\n",
    "    predicted_class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Покажемо реальну мітку (якщо можна отримати з імені файлу)\n",
    "    true_label = os.path.basename(os.path.dirname(img_path))  # Отримуємо категорію з шляху\n",
    "    ax.set_title(f\"Реальна: {true_label}\\nПрогноз: {class_names[predicted_class_idx]} ({confidence:.2f})\", fontsize=12, color=\"red\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "predict_and_plot('../../classification/animal/data/snakes/2_0958.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0003.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0005.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/cats/0_0993.jpg', model, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(img_path, model, class_names, image_size=(256, 256)):\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    pred = model.predict(img_array, verbose=0)[0]\n",
    "    predicted_class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    print(\"Прогноз:\", predicted_class_idx, \"->\", class_names[predicted_class_idx])\n",
    "    print(\"Ймовірності:\", pred)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Прогноз: {class_names[predicted_class_idx]} ({confidence:.2f})\")\n",
    "    plt.show()\n",
    "\n",
    "predict_and_plot('../../classification/animal/data/snakes/2_0958.jpg', model, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(img_path, model, class_names, image_size=(256, 256)):\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    # pred = model.predict(img_array)[0]\n",
    "    # pred = tf.squeeze(model.predict(img_array)).numpy()\n",
    "    pred = model.predict(img_array, verbose=0)[0]\n",
    "\n",
    "    predicted_class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Прогноз: {class_names[predicted_class_idx]} ({confidence:.2f})\")\n",
    "    plt.show()\n",
    "\n",
    "predict_and_plot('../../classification/animal/data/snakes/2_0958.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0003.jpg', model, class_names)\n",
    "predict_and_plot('../../classification/animal/data/dogs/1_0005.jpg', model, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5. Побудова моделі на базі MobileNetV2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int')\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def preprocess_data(image, label):\n",
    "    label = tf.one_hot(label, depth=len(class_names))  # One-hot encoding\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess_data)\n",
    "test_ds = test_ds.map(preprocess_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image shape:\", images.shape)  # Має бути (batch_size, 256, 256, 3)\n",
    "    print(\"Label shape:\", labels.shape)  # Має бути (batch_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNetV2\n",
    "from keras import layers, models\n",
    "\n",
    "base_model = MobileNetV2(input_shape=image_size + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=10, callbacks=[early_stop])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(img_path, model, class_names, image_size=image_size):\n",
    "    img = load_img(img_path, target_size=image_size)  # Завантаження\n",
    "    img_array = img_to_array(img)  # Перетворення у масив\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)  # Препроцесинг\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Додаємо batch розмір (1, h, w, 3)\n",
    "\n",
    "    pred = model.predict(img_array, verbose=0)[0]\n",
    "    predicted_class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "\n",
    "    plt.imshow(img_array[0].astype(\"uint8\"))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Прогноз: {class_names[predicted_class_idx]} ({confidence:.2f})\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
